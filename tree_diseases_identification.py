# -*- coding: utf-8 -*-
"""Tree_diseases_identification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j_N6yqpS48ObcbtLEHWXjPQlpNIDOD4v
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/My\ Drive/archive.zip

# Distribution graphs (histogram/bar graph) of column data
def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):
    nunique = df.nunique()
    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values
    nRow, nCol = df.shape
    columnNames = list(df)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(nGraphRow, nGraphPerRow, i + 1)
        columnDf = df.iloc[:, i]
        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):
            valueCounts = columnDf.value_counts()
            valueCounts.plot.bar()
        else:
            columnDf.hist()
        plt.ylabel('counts')
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

# prompt: Set the directory paths

train_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'
validation_dir = '/content/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'

# prompt: Check the contents of the dataset directory

!ls {train_dir}
!ls {validation_dir}

# Distribution graphs (histogram/bar graph) of column data
def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):
    nunique = df.nunique()
    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values
    nRow, nCol = df.shape
    columnNames = list(df)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(nGraphRow, nGraphPerRow, i + 1)
        columnDf = df.iloc[:, i]
        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):
            valueCounts = columnDf.value_counts()
            valueCounts.plot.bar()
        else:
            columnDf.hist()
        plt.ylabel('counts')
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

# Correlation matrix
def plotCorrelationMatrix(df, graphWidth):
    filename = df.dataframeName
    df = df.dropna('columns')
    df = df[[col for col in df if df[col].nunique() > 1]]
    if df.shape[1] < 2:
        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')
        return
    corr = df.corr()
    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')
    corrMat = plt.matshow(corr, fignum = 1)
    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)
    plt.yticks(range(len(corr.columns)), corr.columns)
    plt.gca().xaxis.tick_bottom()
    plt.colorbar(corrMat)
    plt.title(f'Correlation Matrix for {filename}', fontsize=15)
    plt.show()

# Scatter and density plots
def plotScatterMatrix(df, plotSize, textSize):
    df = df.select_dtypes(include =[np.number]) # keep only numerical columns
    # Remove rows and columns that would lead to df being singular
    df = df.dropna('columns')
    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values
    columnNames = list(df)
    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots
        columnNames = columnNames[:10]
    df = df[columnNames]
    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')
    corrs = df.corr().values
    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):
        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)
    plt.suptitle('Scatter and Density Plot')
    plt.show()

# Install nightly package for some functionalities that aren't in alpha
!pip install tf-nightly-gpu-2.0-preview

# Install TF Hub for TF2
!pip install 'tensorflow-hub == 0.4'

!pip install tensorflow==2.8.0 tensorflow-hub==0.12.0

from __future__ import absolute_import, division, print_function, unicode_literals


import tensorflow as tf
#tf.logging.set_verbosity(tf.logging.ERROR)
#tf.enable_eager_execution()

import tensorflow_hub as hub
import os
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers
#from keras import optimizers

# verify TensorFlow version

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.test.is_gpu_available() else "NOT AVAILABLE")

import time
import os
from os.path import exists

def count(dir, counter=0):
    "returns number of files in dir and subdirs"
    for pack in os.walk(dir):
        for f in pack[2]:
            counter += 1
    return dir + " : " + str(counter) + "files"

print('total images for training :', count(train_dir))
print('total images for validation :', count(validation_dir))

print(f"Train directory: {train_dir}")

if os.path.exists(train_dir):
    print(os.listdir(train_dir))
else:
    print("Train directory does not exist.")

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Assuming you have already defined data_dir, train_dir, and validation_dir
BATCH_SIZE = 100
IMG_HEIGHT = 224
IMG_WIDTH = 224

image_generator = ImageDataGenerator(rescale=1./255)

# prompt: Label mapping


train_data_gen = image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                     directory=train_dir,
                                                     shuffle=True,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     class_mode='categorical')

class_names = list(train_data_gen.class_indices.keys())
print(class_names)

# prompt: count train data foulder

import os

train_count = len(os.listdir(train_dir))
print(f"Train data folder count: {train_count}")



# prompt: TensorFlow Hub to load a model as a feature extractor.

# Load the pre-trained model from TensorFlow Hub
feature_extractor_url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
feature_extractor_layer = hub.KerasLayer(feature_extractor_url,
                                         input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))

# Freeze the pre-trained layers
feature_extractor_layer.trainable = False

import tensorflow_hub as hub
from tensorflow.keras.applications import MobileNetV2  # Example base model

# Define the module handle and base model
MODULE_HANDLE = "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"
IMAGE_SIZE = (224, 224)
FV_SIZE = 1280  # Example feature vector size

# Load the feature extractor
feature_extractor = hub.KerasLayer(MODULE_HANDLE,
                                   input_shape=IMAGE_SIZE + (3,),
                                   output_shape=[FV_SIZE],
                                   trainable=False)  # By default, set to non-trainable

# Define the base model (e.g., MobileNetV2) if you need to fine-tune
base_model = MobileNetV2(input_shape=IMAGE_SIZE + (3,), include_top=False)

# Fine-tuning control
do_fine_tuning = False  # Set to True if you want to fine-tune

if do_fine_tuning:
    feature_extractor.trainable = True  # Make the feature extractor trainable
    # Unfreeze the last 30 layers for fine-tuning
    for layer in base_model.layers[-30:]:
        layer.trainable = True
else:
    feature_extractor.trainable = False  # Keep the feature extractor non-trainable

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
import tensorflow_hub as hub

# Define the feature extractor
MODULE_HANDLE = "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"
IMAGE_SIZE = (224, 224)

# Load the feature extractor layer from TensorFlow Hub
feature_extractor_layer = hub.KerasLayer(MODULE_HANDLE, input_shape=IMAGE_SIZE + (3,), trainable=False)

# Create the model
model = tf.keras.Sequential([
    feature_extractor_layer,
    layers.Flatten(),  # Flatten the multi-dimensional output from the feature extractor
    layers.Dense(512, activation='relu'),  # Optional dense layer for further processing
    layers.Dense(train_data_gen.num_classes, activation='softmax')  # Output layer
])

# Compile the model
model.compile(
    optimizer=Adam(epsilon=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Print the model summary
model.summary()

# prompt: Specify Loss Function and Optimizer

# Compile the model
model.compile(
    optimizer=Adam(epsilon=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Initialize the ImageDataGenerator for validation data (usually no data augmentation for validation)
image_generator = ImageDataGenerator(rescale=1./255)

# Define directories and parameters

IMG_HEIGHT = 150
IMG_WIDTH = 150
BATCH_SIZE = 32

# Data Preprocessing
val_data_gen = image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                   directory=validation_dir,
                                                   shuffle=False,
                                                   target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                   class_mode='categorical')

# Count the number of files in the validation folder
val_count = len(os.listdir(validation_dir))
print(f"Validation data folder count: {val_count}")

# Data Preprocessing
val_data_gen = image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                   directory=validation_dir,
                                                   shuffle=False,
                                                   target_size=(224, 224), # Changed to match the model's input size
                                                   class_mode='categorical')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Set consistent image size for MobileNetV2 (224x224)
IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 32
EPOCHS = 5
NUM_CLASSES = 38  # Update to the number of classes in your dataset

# Data augmentation for training data
train_image_generator = ImageDataGenerator(rescale=1./255)

# No augmentation for validation data
validation_image_generator = ImageDataGenerator(rescale=1./255)

# Load training data
train_data_gen = train_image_generator.flow_from_directory(
    directory=train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Load validation data
val_data_gen = validation_image_generator.flow_from_directory(
    directory=validation_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Check the number of training and validation samples
train_count = train_data_gen.samples
val_count = val_data_gen.samples

# Build the model using MobileNetV2 as the base
base_model = MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')

# Add custom layers on top of MobileNetV2
x = base_model.output
x = GlobalAveragePooling2D()(x)  # Ensure pooling to avoid size mismatch
x = Dense(512, activation='relu')(x)  # Optional dense layer
predictions = Dense(NUM_CLASSES, activation='softmax')(x)  # Output layer

# Combine base model and new custom layers
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the base model (MobileNetV2) layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer=Adam(epsilon=0.01),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Model training
history = model.fit(
    train_data_gen,
    steps_per_epoch=train_count // BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=val_data_gen,
    validation_steps=val_count // BATCH_SIZE
)

# Optionally, you can unfreeze some layers for fine-tuning after the initial training

# prompt: Plot training and validation accuracy and loss

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(EPOCHS)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# prompt: Random sample images from validation dataset and predict

import numpy as np
import matplotlib.pyplot as plt

# Get a batch of validation data
images, labels = next(val_data_gen)

# Choose a random sample of images
num_samples = 5  # Number of images to sample
random_indices = np.random.choice(images.shape[0], size=num_samples, replace=False)
sampled_images = images[random_indices]
sampled_labels = labels[random_indices]

# Make predictions
predictions = model.predict(sampled_images)

# Display the images and predictions
for i in range(num_samples):
  plt.imshow(sampled_images[i])
  plt.title(f"Predicted: {class_names[np.argmax(predictions[i])]}, Actual: {class_names[np.argmax(sampled_labels[i])]}")
  plt.show()

!pip install tensorflow

import tensorflow as tf

#Set consistent image size for MobileNetV2 (224x224)
IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 32
EPOCHS = 5
NUM_CLASSES = 38  # Update to the number of classes in your dataset

# *** Add this line to define train_dir with the path to your training data
train_dir = '/path/to/your/training/data'

# Data augmentation for training data
train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

# No augmentation for validation data
validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

# Load training data
train_data_gen = train_image_generator.flow_from_directory(
    directory=train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Load validation data
# *** Add this line to define validation_dir with the path to your validation data
validation_dir = '/path/to/your/validation/data'

val_data_gen = validation_image_generator.flow_from_directory(
    directory=validation_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Check the number of training and validation samples
train_count = train_data_gen.samples
val_count = val_data_gen.samples

# Build the model using MobileNetV2 as the base
base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), include_top=False, weights='imagenet')

# Add custom layers on top of MobileNetV2
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)  # Ensure pooling to avoid size mismatch
x = tf.keras.layers.Dense(512, activation='relu')(x)  # Optional dense layer
predictions = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)  # Output layer

# Combine base model and new custom layers
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)

# Freeze the base model (MobileNetV2) layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(epsilon=0.01),
              loss='categorical_crossentropy',
              metrics=['accuracy'])


# Convert the model to TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the TFLite model to a file
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

# Convert the model to TensorFlow Lite format here
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model as a .tflite file
with open('tree_disease_model.tflite', 'wb') as f:
    f.write(tflite_model)